{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add a new cell, type '# %%'\n",
    "# To add a new markdown cell, type '# %% [markdown]'\n",
    "# %%\n",
    "import os\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Finetune Llama-2-13b on an A6000\n",
    "#\n",
    "# Welcome to this LambdaLabs notebook that shows how to fine-tune the recent Llama-2-13b model on a single GPU.\n",
    "#\n",
    "# We will leverage PEFT library from Hugging Face ecosystem, as well as QLoRA for more memory efficient finetuning\n",
    "\n",
    "# %%\n",
    "os.system(\"nvcc --version\")\n",
    "\n",
    "# %%\n",
    "os.system(\"nvidia-smi\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Setup\n",
    "#\n",
    "# Run the cells below to setup and install the required libraries. For our experiment we will need `accelerate`, `peft`, `transformers`, `datasets` and TRL to leverage the recent [`SFTTrainer`](https://huggingface.co/docs/trl/main/en/sft_trainer). We will use `bitsandbytes` to [quantize the base model into 4bit](https://huggingface.co/blog/4bit-transformers-bitsandbytes).\n",
    "\n",
    "# %%\n",
    "os.system(\"pip install -q -U trl transformers accelerate protobuf==3.19.0\")\n",
    "os.system(\"pip install -q datasets bitsandbytes einops wandb\")\n",
    "os.system(\"pip install -q git+https://github.com/huggingface/peft\")\n",
    "\n",
    "\n",
    "# %%\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "\n",
    "# %%\n",
    "os.system(\"pip list\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Dataset\n",
    "#\n",
    "# For our experiment, we will use the `ehartford/dolphin` dataset to train general purpose instruct model.\n",
    "# The dataset can be found [here](https://huggingface.co/datasets/ehartford/dolphin)\n",
    "#\n",
    "\n",
    "# %%\n",
    "seed = 42\n",
    "\n",
    "\n",
    "# %%\n",
    "dataset_name = \"ehartford/dolphin\"\n",
    "print(f\"\\nLoading {dataset_name} dataset...\")\n",
    "dataset_dolphin = load_dataset(dataset_name, split=\"train\", streaming=True)\n",
    "\n",
    "# grab the first 110000 entries in an instruction format\n",
    "dataset_head = dataset_dolphin.take(110000)\n",
    "questions = []\n",
    "responses = []\n",
    "\n",
    "for row in dataset_head:\n",
    "    questions.append(f'{row[\"instruction\"]} {row[\"input\"]}')\n",
    "    responses.append(row[\"output\"])\n",
    "\n",
    "pandas_dataset_dolphin = pd.DataFrame([questions, responses]).T\n",
    "pandas_dataset_dolphin.columns = [\"prompt\", \"response\"]\n",
    "\n",
    "dataset_dolphin_train = Dataset.from_pandas(pandas_dataset_dolphin.iloc[0:100000, :])\n",
    "# remove old text cols\n",
    "dataset_dolphin_train = dataset_dolphin_train.remove_columns(\n",
    "    [\n",
    "        col\n",
    "        for col in dataset_dolphin_train.column_names\n",
    "        if col not in [\"prompt\", \"response\"]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Print an example in the train dataset:\")\n",
    "print(dataset_dolphin_train)\n",
    "print(dataset_dolphin_train[0])\n",
    "\n",
    "print(\"Final train dataset:\")\n",
    "train_dataset = dataset_dolphin_train.shuffle(seed=seed)\n",
    "print(train_dataset)\n",
    "print(train_dataset[0])\n",
    "print(train_dataset[-1])\n",
    "\n",
    "dataset_dolphin_eval = Dataset.from_pandas(pandas_dataset_dolphin.iloc[100000:, :])\n",
    "# remove old text cols\n",
    "dataset_dolphin_eval = dataset_dolphin_eval.remove_columns(\n",
    "    [\n",
    "        col\n",
    "        for col in dataset_dolphin_eval.column_names\n",
    "        if col not in [\"prompt\", \"response\"]\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Print an example in the eval dataset:\")\n",
    "print(dataset_dolphin_eval)\n",
    "print(dataset_dolphin_eval[0])\n",
    "\n",
    "print(\"Final eval dataset:\")\n",
    "eval_dataset = dataset_dolphin_eval.shuffle(seed=seed)\n",
    "print(eval_dataset)\n",
    "print(eval_dataset[0])\n",
    "print(eval_dataset[-1])\n",
    "\n",
    "# let's now write a function to format the dataset for instruction fine-tuning\n",
    "\n",
    "\n",
    "def formatting_prompts_func(dataset):\n",
    "    instructions = []\n",
    "    for i in range(len(dataset[\"prompt\"])):\n",
    "        text = f\"{dataset['prompt'][i]}\\n{dataset['response'][i]}\"\n",
    "        instructions.append(text)\n",
    "    return instructions\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Loading the model\n",
    "# %% [markdown]\n",
    "# In this section we will load the [Llama 2 13B model](https://huggingface.co/meta-llama/Llama-2-13b-hf), quantize it in 4bit and attach LoRA adapters on it. Let's get started!\n",
    "\n",
    "# %%\n",
    "model_name = \"meta-llama/Llama-2-13b-hf\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    use_auth_token=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "model.config.use_cache = False\n",
    "\n",
    "\n",
    "# %%\n",
    "model\n",
    "\n",
    "# %% [markdown]\n",
    "# Let's also load the tokenizer below\n",
    "\n",
    "# %%\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# %% [markdown]\n",
    "# Below we will load the configuration file in order to create the LoRA model. According to QLoRA paper, it is important to consider all linear layers in the transformer block for maximum performance. Therefore we will add `q_proj`, `k_proj`, `v_proj`, `o_proj` layers in the target modules.\n",
    "\n",
    "# %%\n",
    "lora_alpha = 16\n",
    "lora_dropout = 0.1\n",
    "lora_r = 64\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Loading the trainer\n",
    "# %% [markdown]\n",
    "# Here we will use the [`SFTTrainer` from TRL library](https://huggingface.co/docs/trl/main/en/sft_trainer) that gives a wrapper around transformers `Trainer` to easily fine-tune models on instruction based datasets using PEFT adapters. Let's first load the training arguments below.\n",
    "\n",
    "# %%\n",
    "output_dir = \"./results\"\n",
    "num_train_epochs = 1\n",
    "auto_find_batch_size = True\n",
    "gradient_accumulation_steps = 1\n",
    "optim = \"paged_adamw_32bit\"\n",
    "save_strategy = \"epoch\"\n",
    "learning_rate = 2e-4\n",
    "lr_scheduler_type = \"constant_with_warmup\"\n",
    "warmup_ratio = 0.03\n",
    "logging_strategy = \"steps\"\n",
    "logging_steps = 25\n",
    "do_eval = True\n",
    "evaluation_strategy = \"steps\"\n",
    "prediction_loss_only = True\n",
    "eval_steps = 0.2\n",
    "bf16 = True\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    auto_find_batch_size=auto_find_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_strategy=save_strategy,\n",
    "    learning_rate=learning_rate,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    logging_strategy=logging_strategy,\n",
    "    logging_steps=logging_steps,\n",
    "    do_eval=do_eval,\n",
    "    evaluation_strategy=evaluation_strategy,\n",
    "    prediction_loss_only=prediction_loss_only,\n",
    "    eval_steps=eval_steps,\n",
    "    bf16=bf16,\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# Then finally pass everthing to the trainer\n",
    "\n",
    "# %%\n",
    "max_seq_length = 4096\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    formatting_func=formatting_prompts_func,\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# We will also pre-process the model by upcasting the layer norms in float 32 for more stable training\n",
    "\n",
    "# %%\n",
    "for name, module in trainer.model.named_modules():\n",
    "    if \"norm\" in name:\n",
    "        module = module.to(torch.float32)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Train the model\n",
    "# %% [markdown]\n",
    "# Now let's train the model! Simply call `trainer.train()`\n",
    "\n",
    "# %%\n",
    "trainer.train()\n",
    "\n",
    "# wandb: Currently logged in as: dryanfurman. Use `wandb login --relogin` to force relogin\n",
    "# wandb: Tracking run with wandb version 0.15.5\n",
    "# wandb: Run data is saved locally in /home/ubuntu/wandb/run-20230723_071649-pohixish\n",
    "# wandb: Run `wandb offline` to turn off syncing.\n",
    "# wandb: Syncing run dulcet-blaze-13 to Weights & Biases (docs)\n",
    "# wandb: ⭐️ View project at https://wandb.ai/dryanfurman/huggingface\n",
    "# wandb: 🚀 View run at View run at https://wandb.ai/dryanfurman/huggingface/runs/pohixish"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
