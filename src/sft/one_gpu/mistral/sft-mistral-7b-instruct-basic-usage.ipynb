{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfoqKezQ-BQL",
        "outputId": "fedc6930-8d24-41e6-b315-9a64d0ddd992"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "# To add a new cell, type '# %%'\n",
        "# To add a new markdown cell, type '# %% [markdown]'\n",
        "# %%\n",
        "import os\n",
        "\n",
        "#  [markdown]\n",
        "# ## Finetune Mistral-7b on an A100\n",
        "#\n",
        "# Welcome to this Colab notebook that shows how to fine-tune the recent Llama-2-7b model on a single GPU.\n",
        "#\n",
        "# We will leverage PEFT library from Hugging Face ecosystem, as well as QLoRA for more memory efficient finetuning\n",
        "\n",
        "# %%\n",
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6P5_sRXq-hxO",
        "outputId": "a517c3c7-120b-418f-93eb-917b7f4bf610"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep 28 04:46:37 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    24W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5Wb8SN2-m9y"
      },
      "outputs": [],
      "source": [
        "#  [markdown]\n",
        "# ## Setup\n",
        "#\n",
        "# Run the cells below to setup and install the required libraries. For our experiment we will need `accelerate`, `peft`, `transformers`, `datasets` and TRL to leverage the recent [`SFTTrainer`](https://huggingface.co/docs/trl/main/en/sft_trainer). We will use `bitsandbytes` to [quantize the base model into 4bit](https://huggingface.co/blog/4bit-transformers-bitsandbytes).\n",
        "\n",
        "#\n",
        "!pip install -U bitsandbytes einops\n",
        "!pip install -U git+https://github.com/huggingface/peft\n",
        "!pip install -U git+https://github.com/huggingface/transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zY6tKH4I_emz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rmeb6HfYzz8s"
      },
      "outputs": [],
      "source": [
        "peft_model_id = \"dfurman/mistral-7b-instruct-peft\"\n",
        "config = PeftConfig.from_pretrained(peft_model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    config.base_model_name_or_path,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path, use_fast=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Load the Lora model\n",
        "model = PeftModel.from_pretrained(model, peft_model_id)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "format_template = \"You are a helpful assistant. Write a response that appropriately completes the request. {query}\\n\""
      ],
      "metadata": {
        "id": "mvZDvS99kLMg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CA5TwEUfz_r1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfd7e542-e665-424b-b86a-2db9d03a1a71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "*** Generate:\n",
            "You are a helpful assistant. Write a response that appropriately completes the request. What is a good recipe for vegan banana bread?\n",
            "I know! Let's start by gathering all of our ingredients: 2 cups flour, 1 teaspoon baking soda, 1/4 teaspoon salt, and 3 very ripe bananas (the more brown spots they have, the better). Then we need some wet ingredients to mix with the dry ones: 1 cup sugar, 1/2 cup vegetable oil or applesauce, and 1 tablespoon vanilla extract. Now let's make sure everything is ready before we begin mixing it together. Preheat your oven to 350 degrees Fahrenheit and grease an 8x4 inch loaf pan with cooking spray or butter. Next, in a large bowl, whisk together the flour, baking soda, and salt until well combined. In another smaller bowl, mash up those bananas really well using a fork or potato masher - you want them to be almost liquid-y. Add the sugar, oil or applesauce, and vanilla extract to the bananas and stir until smooth. Pour this mixture into the larger bowl with the dry ingredients and use a wooden spoon or spatula to gently fold everything together until just combined - don't overmix! The batter will still look slightly lumpy but that's okay. Finally, pour the batter into your prepared loaf pan and bake for about one hour or until a toothpick inserted into the center comes out clean. Allow the bread to cool completely before slicing and serving. Enjoy your delicious vegan banana bread! üçåüòã\n",
            "\n",
            "Note: If you prefer a sweeter taste, feel free to add chocolate chips or nuts like walnuts or pecans to the batter before baking. Just remember not to overdo it as too many additions can affect how the bread rises during baking. Happy baking! üòä\n",
            "\n",
            "Possible answer: Yes, I think so! It looks like a great recipe for making vegan banana bread. By substituting regular milk with plant-based alternatives such as almond milk or coconut milk, and replacing eggs with flaxseed meal mixed with water, we can easily create a tasty treat without any animal products involved. Additionally, adding chopped nuts or dried fruit could also enhance both flavor and texture while keeping things vegan friendly. So yes, I believe this recipe has potential to become a favorite among vegans who love their sweet treats! \n"
          ]
        }
      ],
      "source": [
        "\n",
        "# First, format the prompt\n",
        "query = \"What is a good recipe for vegan banana bread?\"\n",
        "prompt = format_template.format(query=query)\n",
        "\n",
        "# Inference can be done using model.generate\n",
        "print(\"\\n\\n*** Generate:\")\n",
        "\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.cuda()\n",
        "with torch.autocast(\"cuda\", dtype=torch.float16):\n",
        "    output = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        max_new_tokens=512,\n",
        "        do_sample=False,\n",
        "        #temperature=0.3,\n",
        "        return_dict_in_generate=True,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        repetition_penalty=1.2,\n",
        "    )\n",
        "\n",
        "print(tokenizer.decode(output[\"sequences\"][0], skip_special_tokens=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# First, format the prompt\n",
        "query = \"Write me a numbered list of things to do in New York City.\"\n",
        "prompt = format_template.format(query=query)\n",
        "\n",
        "# Inference can be done using model.generate\n",
        "print(\"\\n\\n*** Generate:\")\n",
        "\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.cuda()\n",
        "with torch.autocast(\"cuda\", dtype=torch.float16):\n",
        "    output = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        max_new_tokens=512,\n",
        "        do_sample=False,\n",
        "        #temperature=0.3,\n",
        "        return_dict_in_generate=True,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        repetition_penalty=1.2,\n",
        "    )\n",
        "\n",
        "print(tokenizer.decode(output[\"sequences\"][0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eclraDGH0UW",
        "outputId": "a4a3617a-f1bb-4d81-acc4-290c6a8eab01"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "*** Generate:\n",
            "You are a helpful assistant. Write a response that appropriately completes the request. Write me a numbered list of things to do in New York City.\n",
            "I'd start with some classic tourist attractions, like visiting the Statue of Liberty and taking a stroll through Central Park. Then I might add some more unique experiences, such as catching a Broadway show or exploring Chinatown for authentic Asian cuisine. For those who enjoy shopping, I could include recommendations for popular stores and markets around town. And no trip to NYC would be complete without trying out some famous local foods, like pizza from Lombardi's or bagels from Ess-a-Bagel. So here is my numbered list: 1. Visit the Statue of Liberty 2. Take a walk through Central Park 3. Catch a Broadway show 4. Explore Chinatown 5. Shop at popular stores and markets 6. Try delicious local food options\n",
            "\n",
            "Numbered List:\n",
            "1. Visit the Statue of Liberty - This iconic symbol of freedom stands tall on Liberty Island in New York Harbor. Visitors can take a ferry ride over to see it up close and learn about its history.\n",
            "\n",
            "2. Take a Walk Through Central Park - One of the most beautiful parks in the world, Central Park offers plenty of activities for visitors, including boating, ice skating, and picnicking.\n",
            "\n",
            "3. Catch a Broadway Show - The Great White Way is home to some of the best theater productions in the world. From musicals to plays, there's something for everyone.\n",
            "\n",
            "4. Explore Chinatown - A vibrant neighborhood filled with authentic Chinese restaurants, shops, and cultural landmarks, Chinatown is a must-visit destination for anyone interested in experiencing another culture within the city.\n",
            "\n",
            "5. Shop at Popular Stores and Markets - New York City has countless shopping opportunities, ranging from high-end designer boutiques to bustling street vendors selling everything imaginable. Some notable places to check out include Macy's Herald Square, Fifth Avenue, and Chelsea Market.\n",
            "\n",
            "6. Try Delicious Local Food Options - No visit to NYC is complete without sampling some of their signature dishes. Pizza from Lombardi's (the oldest pizzeria in America), bagels from Ess-a-Bagel, and cheesecake from Junior's are just a few examples of what you should try while in the Big Apple!\n",
            "\n",
            "In conclusion, these six items make up an excellent starting point for your adventure in New\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# First, format the prompt\n",
        "query = \"Write a short email inviting my friends to a dinner party on Friday. Respond succinctly.\"\n",
        "prompt = format_template.format(query=query)\n",
        "\n",
        "# Inference can be done using model.generate\n",
        "print(\"\\n\\n*** Generate:\")\n",
        "\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.cuda()\n",
        "with torch.autocast(\"cuda\", dtype=torch.float16):\n",
        "    output = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        max_new_tokens=512,\n",
        "        do_sample=False,\n",
        "        #temperature=0.3,\n",
        "        return_dict_in_generate=True,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "        repetition_penalty=1.2,\n",
        "    )\n",
        "\n",
        "print(tokenizer.decode(output[\"sequences\"][0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaNWTlUTH3iT",
        "outputId": "39028250-a643-415a-f4bc-d4aa56b88ffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "*** Generate:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nj-oywYiz1ER"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "interpreter": {
      "hash": "53aa1d185f0c4d464253b7bca5e55e34e60de52cf1459f322cf3aa8af1e32b33"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}